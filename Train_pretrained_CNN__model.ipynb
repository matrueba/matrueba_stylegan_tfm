{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_pretrained_CNN _model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZWiI0NsyoIY"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, BatchNormalization, Flatten, Dropout, Input, MaxPooling2D\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,recall_score\n",
        "import itertools\n",
        "import warnings\n",
        "from sklearn import metrics\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDhJltsJ0A5E"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKA2J5540Bpj"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFSSdJTeKHg9"
      },
      "source": [
        "Load train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFiVpjpf0FJv"
      },
      "source": [
        "train_folder = \"\"\n",
        "train_data = image_dataset_from_directory(train_folder,\n",
        "    label_mode=\"binary\",\n",
        "    labels=\"inferred\",\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True)\n",
        "\n",
        "rescale = Rescaling(scale=1.0/255)\n",
        "train_data = train_data.map(lambda image,label:(rescale(image),label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx63KIgiKMVi"
      },
      "source": [
        "Load test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--BLscbqGaM5"
      },
      "source": [
        "test_folder =  \"\"\n",
        "test_data = image_dataset_from_directory(test_folder,\n",
        "    label_mode=\"binary\",\n",
        "    labels=\"inferred\",\n",
        "    batch_size=32,\n",
        "    image_size=(128, 128),\n",
        "    shuffle=True)\n",
        "\n",
        "rescale = Rescaling(scale=1.0/255)\n",
        "test_data = test_data.map(lambda image,label:(rescale(image),label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gPKc_3xKSNc"
      },
      "source": [
        "Import pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxRoCpf1GVUg"
      },
      "source": [
        "pretrained_model = VGG16(include_top=False, input_shape=(128,128,3))\n",
        "for layer in pretrained_model.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzyVpQFWKReJ"
      },
      "source": [
        "Build CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Slc9FMsHFs_"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(pretrained_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DxQECquHhgr"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv1Q1TTAKYC4"
      },
      "source": [
        "Define training callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1V8GwzdTbe"
      },
      "source": [
        "checkpoint_path = \"\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0X2mCgNKeEG"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWU2unnuPfLD"
      },
      "source": [
        "history = model.fit(  \n",
        "    train_data,\n",
        "    epochs=100,\n",
        "    validation_data=test_data,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K825Dq-rKgOl"
      },
      "source": [
        "Plot training graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBoHAe56ylqv"
      },
      "source": [
        "acc = list(map(lambda x: x * 100, history.history['accuracy']))\n",
        "val = list(map(lambda x: x * 100, history.history['val_accuracy']))\n",
        "plt.plot(acc)\n",
        "plt.plot(val)\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy (%)')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVjazcYKjMT"
      },
      "source": [
        "Compute metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnHfaHORtnOM"
      },
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "pred = []\n",
        "lab =  []\n",
        "for x, y in test_data:\n",
        "  pred.append(np.round(model.predict(x)))\n",
        "  lab.append(y.numpy())\n",
        "  \n",
        "predictions = np.concatenate(pred)\n",
        "labels = np.concatenate(lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_N220yM-8Pz"
      },
      "source": [
        "print(metrics.accuracy_score(labels, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xms6UgWVODjm"
      },
      "source": [
        "print(classification_report(predictions,  labels, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiiqqw6cKlcJ"
      },
      "source": [
        "Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PckUH-3mOpvC"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "                          \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zZy2uEzOpzE"
      },
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(predictions,  labels)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(5, 5))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['covid', 'normal'],\n",
        "                      title='Confusion matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3HMwWbNKqk1"
      },
      "source": [
        "Compute evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeeCaaNmyptB"
      },
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJ6FJ6fyrDZ"
      },
      "source": [
        "TP, FP, TN, FN = perf_measure(predictions, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxbvXWW_KvMC"
      },
      "source": [
        "Plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uvonYhkoxn9"
      },
      "source": [
        "fpr, tpr, thresholds= metrics.roc_curve(predictions, labels)\n",
        "auc = metrics.auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqGm5ZkZo8Kf"
      },
      "source": [
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='AUC (area = {:.3f})'.format(auc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}